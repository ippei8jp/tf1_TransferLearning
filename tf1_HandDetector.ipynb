{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"tf1_HandDetector.ipynb","provenance":[],"collapsed_sections":[],"toc_visible":true,"history_visible":true,"mount_file_id":"1JGau6F2MYc1hF15m5y5eeKYD8jMULRCt","authorship_tag":"ABX9TyOFLT2HZaCFwqAKLPBp8EnV"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU"},"cells":[{"cell_type":"markdown","metadata":{"id":"_ksCkbvgvr5T"},"source":["以下の参考サイトの手順をTensorflow1で実行するように変更した。  \n","参考：  https://towardsdatascience.com/train-an-object-detector-using-tensorflow-2-object-detection-api-in-2021-a4fed450d1b9"]},{"cell_type":"markdown","metadata":{"id":"Z2etjP2Rou_b"},"source":["# 事前準備\n","ランタイム→ランタイムのタイプを変更を選択、ハードウェアアクセラレータを「GPU」に変更しておく。\n","\n","\n","# GoogleDriveのマウント\n","GoogleDrive上にファイルを保存する場合は以下のセルを実行してカレントディレクトリを移動しておく(CTRL+M Yでコードセル化)。    \n","ただし、3GByte程度消費するので空き容量に注意。  \n","不要な場合はスキップする(CTRL+M Mでテキストセル化)。    \n"]},{"cell_type":"markdown","metadata":{"id":"LxOSwlbkonaH"},"source":["from google.colab import drive\n","drive.mount('/content/drive')\n","%cd /content/drive/MyDrive"]},{"cell_type":"markdown","metadata":{"id":"7p-XPLJqQjnx"},"source":["# Tensorflowのバージョンを1.xに変更する。"]},{"cell_type":"code","metadata":{"id":"7YVcdijWNqph"},"source":["%tensorflow_version 1.x"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"Ishd8f-vuvxl"},"source":["【NOTE】  \n","以下でTensorflowのバージョンを変更しようとすると、なぜかCPU版になってしまう。\n","``tensorflow-gpu``だとtensorflowが見つからないと怒られる。  \n","```\n","!pip uninstall -y tensorflow\n","!pip install --upgrade tensorflow-gpu==1.15.5\n","```"]},{"cell_type":"markdown","metadata":{"id":"L1wSuzHuo_Kk"},"source":["# ワークディレクトリの作成と移動"]},{"cell_type":"code","metadata":{"id":"rznKxR4domA1"},"source":["import sys\n","import os\n","\n","!mkdir -p hand_detect_tf1\n","%cd hand_detect_tf1\n","\n","# 現在のディレクトリ\n","CUR_DIR = os.getcwd()"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"eGgG286KpXYt"},"source":["# object-detection モジュールのインストール\n","## gitリポジトリのclone"]},{"cell_type":"code","metadata":{"id":"IoxRr0fxpjUQ"},"source":["%cd $CUR_DIR\n","!git clone --depth 1 https://github.com/tensorflow/models.git"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"kZz6EdUrsZFs"},"source":["## プロトコルバッファのコンパイル"]},{"cell_type":"code","metadata":{"id":"qV-4f2jWpn3w"},"source":["%cd $CUR_DIR/models/research\n","!protoc object_detection/protos/*.proto --python_out=."],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"4at2q1lMssvC"},"source":["## モジュールのインストール"]},{"cell_type":"code","metadata":{"id":"OXo6bRCmqMiJ"},"source":["%cd $CUR_DIR/models/research\n","!cp object_detection/packages/tf1/setup.py .\n","!python -m pip install ."],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"ZqXTho4itAr5"},"source":["## テスト"]},{"cell_type":"code","metadata":{"id":"z2AO1753rlr1"},"source":["%cd $CUR_DIR/models/research\n","!python object_detection/builders/model_builder_tf1_test.py"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"q3qxMI7PwvAW"},"source":["# データセットのダウンロード\n","## gitリポジトリのclone"]},{"cell_type":"code","metadata":{"id":"Y1sv0LdLtHHt"},"source":["%cd $CUR_DIR\n","!git clone https://github.com/aalpatya/detect_hands.git"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"yl6lDbIK3-Bq"},"source":["##  データのダウンロード→csvファイルの生成→tf_recordsの生成"]},{"cell_type":"code","metadata":{"id":"a6DcC6dYw8pr"},"source":["%cd $CUR_DIR\n","!python detect_hands/egohands_dataset_to_csv.py\n","!python detect_hands/generate_tfrecord.py --csv_input=images/train/train_labels.csv  --output_path=train.record\n","!python detect_hands/generate_tfrecord.py --csv_input=images/test/test_labels.csv  --output_path=test.record"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"Xl6mI4uA08MZ"},"source":["# 元となるモデルのダウンロード\n","\n","元になるモデルファイルは以下を参照  \n","https://github.com/tensorflow/models/blob/master/research/object_detection/g3doc/tf1_detection_zoo.md\n"]},{"cell_type":"code","metadata":{"id":"SO_X6UycyinH"},"source":["%cd $CUR_DIR\n","!wget http://download.tensorflow.org/models/object_detection/ssd_mobilenet_v2_coco_2018_03_29.tar.gz\n","!tar xzvf ssd_mobilenet_v2_coco_2018_03_29.tar.gz "],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"t27ugKVj656s"},"source":["## pipline.txtの修正\n","学習処理に合わせて修正する"]},{"cell_type":"code","metadata":{"id":"dp2YfZ0N6-oI"},"source":["%cd $CUR_DIR\n","\n","# 学習回数\n","NUM_STEPS = 80000                  # 回数は要検討\n","\n","# 学習済みモデル出力ディレクトリ\n","TRAINED_DIR = \"output_training\"\n","TRAINED_DIR_ABS = f\"{CUR_DIR}/{TRAINED_DIR}\"\n","!mkdir -p $TRAINED_DIR_ABS\n","\n","ORG_MODEL_NAME = \"ssd_mobilenet_v2_coco_2018_03_29\"\n","\n","# オリジナルCONFIGファイル名\n","ORG_CONFIG_FILE = f\"{CUR_DIR}/{ORG_MODEL_NAME}/pipeline.config\"\n","# オリジナルラベルファイル\n","ORG_LABEL_FILE = f\"{CUR_DIR}/detect_hands/model_data/ssd_mobilenet_v2_fpn_320/label_map.pbtxt\"\n","\n","# CONFIGファイル名\n","CONFIG_FILE = TRAINED_DIR_ABS + \"/pipeline.config\"\n","# ラベルファイル\n","LABEL_FILE = TRAINED_DIR_ABS + \"/label_map.pbtxt\"\n","\n","# それぞれをコピー\n","!cp $ORG_CONFIG_FILE $CONFIG_FILE\n","!cp $ORG_LABEL_FILE $LABEL_FILE\n","\n","# オリジナルCHECKPOINTファイル(学習再開する場合はここを変更)\n","FINE_TUNE_CKPT   = f\"{CUR_DIR}/{ORG_MODEL_NAME}/model.ckpt\"\n","# 学習データ\n","TRAIN_RECORD = f\"{CUR_DIR}/train.record\"\n","# テストデータ\n","TEST_RECORD  = f\"{CUR_DIR}/test.record\"\n","\n","import re\n","from object_detection.protos import pipeline_pb2\n","from google.protobuf import text_format\n","import tensorflow.compat.v1 as tf\n","\n","# オリジナルファイル読み込み\n","pipeline_config = pipeline_pb2.TrainEvalPipelineConfig()\n","with tf.gfile.GFile(CONFIG_FILE, \"r\") as f:\n","  proto_str = f.read()\n","  proto_str = re.sub('batch_norm_trainable:.*\\\\n', '',  proto_str)      # batch_norm_trainable エントリを削除(エラー回避)\n","  text_format.Merge(proto_str, pipeline_config)\n","\n","# パラメータ変更\n","pipeline_config.model.ssd.num_classes                                      = 1\n","\n","pipeline_config.train_config.batch_size                                    = 4\n","pipeline_config.train_config.fine_tune_checkpoint                          = FINE_TUNE_CKPT\n","pipeline_config.train_config.num_steps                                     = NUM_STEPS\n","pipeline_config.train_config.fine_tune_checkpoint_type                     = \"detection\"\n","\n","pipeline_config.train_input_reader.label_map_path                          = LABEL_FILE\n","pipeline_config.train_input_reader.tf_record_input_reader.input_path[0]    = TRAIN_RECORD\n","\n","pipeline_config.eval_input_reader[0].label_map_path                        = LABEL_FILE\n","pipeline_config.eval_input_reader[0].tf_record_input_reader.input_path[0]  = TEST_RECORD\n","\n","# 変更後データの書き込み\n","pipeline_text = text_format.MessageToString(pipeline_config)\n","with tf.gfile.Open(CONFIG_FILE, \"wb\") as f:\n","  f.write(pipeline_text)\n","print(\"DONE\")\n"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"8qsBR_waUmwp"},"source":["# TensorBoardの起動\n","ローカルだとこれでちゃんと結果見れるのに、Google Colab だと見れない...なんで？  "]},{"cell_type":"code","metadata":{"id":"HZcQeTHNUrSp"},"source":["%load_ext tensorboard\n","%tensorboard --logdir=$TRAINED_DIR_ABS"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"L5hqGiXmVRy3"},"source":["# 学習の実行\n","メインイベント  \n","ちょっと時間がかかるのでお茶でも飲んでてください(数時間のオーダー)"]},{"cell_type":"code","metadata":{"id":"cgLESxOPVXHx"},"source":["%cd $CUR_DIR/models/research/object_detection/\n","\n","!python model_main.py \\\n","--pipeline_config_path=$CONFIG_FILE \\\n","--model_dir=$TRAINED_DIR_ABS \\\n","--alsologtostderr"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"prx67pKuywa4"},"source":["# モデルのエクスポート\n","生成したZIPファイルをダウンロードしてください。  "]},{"cell_type":"code","metadata":{"id":"Z98Yb4miy0dp"},"source":["%cd $CUR_DIR/models/research/object_detection\n","EXPORT_DIR = \"inference\"\n","EXPORT_DIR_ABS = f\"{CUR_DIR}/{EXPORT_DIR}\"\n","\n","CHKPT_PREFIX = f\"{TRAINED_DIR_ABS}/model.ckpt-{NUM_STEPS}\"\n","\n","!python export_inference_graph.py \\\n","--input_type image_tensor \\\n","--pipeline_config_path $CONFIG_FILE \\\n","--trained_checkpoint_prefix $CHKPT_PREFIX \\\n","--output_directory $EXPORT_DIR_ABS\n","\n","# ラベルファイルもコピーしておく\n","!cp $LABEL_FILE $EXPORT_DIR_ABS"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"NcfTJS4Ysp87"},"source":["%cd $CUR_DIR\n","\n","import datetime\n","JST = datetime.timezone(datetime.timedelta(hours=+9), 'JST')\n","date_str = datetime.datetime.now(JST).strftime('_%Y%m%d_%H%M%S.zip')\n","zip_filename_export = EXPORT_DIR + date_str\n","zip_filename_trained = TRAINED_DIR + date_str\n","\n","zip_filename = datetime.datetime.now().strftime('hand_detect_%Y%m%d_%H%M%S.zip')\n","!zip -r $zip_filename_export $EXPORT_DIR\n","!zip -r $zip_filename_trained $TRAINED_DIR"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"wWhHVYk5h4Aq"},"source":["# テスト"]},{"cell_type":"code","metadata":{"id":"eu9AyJI3h88r"},"source":["# テスト用画像ファイルのダウンロード\n","!wget https://cdn.amebaowndme.com/madrid-prd/madrid-web/images/sites/483796/1357355de6edbc4c4b54d22faf0b0756_ce052e9b134a9dbb047a8e17c890832a.jpg -O a.jpg\n","!wget https://cdn.amebaowndme.com/madrid-prd/madrid-web/images/sites/483796/564b6ca69e9022aa1977f335a148a05a_2d642c807aaf8f5b972a0a406903447d.jpg -O b.jpg\n"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"gZ75krjCiT0d"},"source":["import os\n","import sys\n","import cv2\n","\n","import numpy as np\n","import tensorflow as tf\n","\n","from PIL import Image\n","from IPython.display import display\n","\n","from object_detection.utils import ops as utils_ops\n","from object_detection.utils import label_map_util\n","from object_detection.utils import visualization_utils as vis_util\n","\n","# patch tf1 into `utils.ops`\n","utils_ops.tf = tf.compat.v1\n","\n","# Patch the location of gfile\n","tf.gfile = tf.io.gfile\n","\n","# ラベルマップのロード\n","PATH_TO_LABELS = CUR_DIR + '/inference/label_map.pbtxt'\n","category_index = label_map_util.create_category_index_from_labelmap(PATH_TO_LABELS, use_display_name=True)\n","\n","# テスト用イメージファイル\n","TEST_IMAGE_PATHS = [\n","                        \"a.jpg\", \n","                        \"b.jpg\",\n","                    ]\n","\n","# モデルのロード\n","PATH_TO_FROZEN_GRAPH = CUR_DIR + \"/inference/frozen_inference_graph.pb\"\n","detection_graph = tf.Graph()\n","with detection_graph.as_default():\n","  od_graph_def = tf.GraphDef()\n","  with tf.gfile.GFile(PATH_TO_FROZEN_GRAPH, 'rb') as fid:\n","    serialized_graph = fid.read()\n","    od_graph_def.ParseFromString(serialized_graph)\n","    tf.import_graph_def(od_graph_def, name='')\n","\n","\n","def load_image_into_numpy_array(image):\n","  (im_width, im_height) = image.size\n","  return np.array(image.getdata()).reshape(\n","      (im_height, im_width, 3)).astype(np.uint8)\n","\n","\n","def run_inference_for_single_image(image, graph):\n","  with graph.as_default():\n","    with tf.Session() as sess:\n","      # Get handles to input and output tensors\n","      ops = tf.get_default_graph().get_operations()\n","      all_tensor_names = {output.name for op in ops for output in op.outputs}\n","      tensor_dict = {}\n","      for key in [\n","          'num_detections', 'detection_boxes', 'detection_scores',\n","          'detection_classes', 'detection_masks'\n","      ]:\n","        tensor_name = key + ':0'\n","        if tensor_name in all_tensor_names:\n","          tensor_dict[key] = tf.get_default_graph().get_tensor_by_name(\n","              tensor_name)\n","      if 'detection_masks' in tensor_dict:\n","        # The following processing is only for single image\n","        detection_boxes = tf.squeeze(tensor_dict['detection_boxes'], [0])\n","        detection_masks = tf.squeeze(tensor_dict['detection_masks'], [0])\n","        # Reframe is required to translate mask from box coordinates to image coordinates and fit the image size.\n","        real_num_detection = tf.cast(tensor_dict['num_detections'][0], tf.int32)\n","        detection_boxes = tf.slice(detection_boxes, [0, 0], [real_num_detection, -1])\n","        detection_masks = tf.slice(detection_masks, [0, 0, 0], [real_num_detection, -1, -1])\n","        detection_masks_reframed = utils_ops.reframe_box_masks_to_image_masks(\n","            detection_masks, detection_boxes, image.shape[0], image.shape[1])\n","        detection_masks_reframed = tf.cast(\n","            tf.greater(detection_masks_reframed, 0.5), tf.uint8)\n","        # Follow the convention by adding back the batch dimension\n","        tensor_dict['detection_masks'] = tf.expand_dims(\n","            detection_masks_reframed, 0)\n","      image_tensor = tf.get_default_graph().get_tensor_by_name('image_tensor:0')\n","\n","      # Run inference\n","      output_dict = sess.run(tensor_dict,\n","                             feed_dict={image_tensor: np.expand_dims(image, 0)})\n","\n","      # all outputs are float32 numpy arrays, so convert types as appropriate\n","      output_dict['num_detections'] = int(output_dict['num_detections'][0])\n","      output_dict['detection_classes'] = output_dict[\n","          'detection_classes'][0].astype(np.uint8)\n","      output_dict['detection_boxes'] = output_dict['detection_boxes'][0]\n","      output_dict['detection_scores'] = output_dict['detection_scores'][0]\n","      if 'detection_masks' in output_dict:\n","        output_dict['detection_masks'] = output_dict['detection_masks'][0]\n","  return output_dict\n","  \n","\n","\n","\n","\n","def show_inference(image_path):\n","  # 画像の読み込み\n","  image = Image.open(image_path)\n","  image_np = load_image_into_numpy_array(image)\n","  image_np_expanded = np.expand_dims(image_np, axis=0)\n","\n","  output_dict = run_inference_for_single_image(image_np, detection_graph)\n","  # Visualization of the results of a detection.\n","  vis_util.visualize_boxes_and_labels_on_image_array(\n","      image_np,\n","      output_dict['detection_boxes'],\n","      output_dict['detection_classes'],\n","      output_dict['detection_scores'],\n","      category_index,\n","      instance_masks=output_dict.get('detection_masks'),\n","      use_normalized_coordinates=True,\n","      line_thickness=8)\n","  # plt.figure(figsize=IMAGE_SIZE)\n","  # plt.imshow(image_np)\n","\n","  # 表示\n","  display(Image.fromarray(image_np))\n","  # ～～～ 単独実行するときの表示処理はこちら ～～～\n","  # new_image = cv2.cvtColor(image_np, cv2.COLOR_RGB2BGR)\n","  # cv2.imshow(\"Detection Results\", new_image)  \n","  # cv2.waitKey(0)\n","  # cv2.destroyAllWindows()\n","\n","# 実行\n","for image_path in TEST_IMAGE_PATHS:\n","  show_inference(image_path)\n","  "],"execution_count":null,"outputs":[]}]}